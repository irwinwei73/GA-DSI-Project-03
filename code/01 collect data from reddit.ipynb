{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to classify posts from the following sub-reddits:\n",
    "- r/TalesFromTheCustomer\n",
    "- r/TalesFromYourServer\n",
    "\n",
    "TalesFromTheCustomer posts generally comprise accounts of poor customer service encountered by contributors.\n",
    "\n",
    "TalesFromYourServer posts mainly comprise contributions from people who work(ed) as waiters/waitresses regarding unreasonable customers they encountered at work.\n",
    "\n",
    "As such, the lexicon/vocabulary in both types of posts are very similar. Hence, the challenge is to create a model that relies not only individual words, but also multi-word sequences to tell the posts apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries/packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set URL for subreddit --- 'Tales From The Customer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.reddit.com/r/TalesFromTheCustomer/new.json?limit=100'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratively retrieve 100 posts. Set maximum iterations to 15. Stop iterating if duplicate posts are detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/TalesFromTheCustomer/new.json?limit=100\n",
      "https://www.reddit.com/r/TalesFromTheCustomer/new.json?limit=100&after=t3_d8x1wd\n",
      "https://www.reddit.com/r/TalesFromTheCustomer/new.json?limit=100&after=t3_cxor6a\n",
      "https://www.reddit.com/r/TalesFromTheCustomer/new.json?limit=100&after=t3_co4m5a\n",
      "https://www.reddit.com/r/TalesFromTheCustomer/new.json?limit=100&after=t3_ch487j\n",
      "https://www.reddit.com/r/TalesFromTheCustomer/new.json?limit=100&after=t3_caqgrw\n",
      "https://www.reddit.com/r/TalesFromTheCustomer/new.json?limit=100&after=t3_c2b93p\n",
      "https://www.reddit.com/r/TalesFromTheCustomer/new.json?limit=100&after=t3_bu4ahw\n",
      "https://www.reddit.com/r/TalesFromTheCustomer/new.json?limit=100&after=t3_bko32k\n",
      "https://www.reddit.com/r/TalesFromTheCustomer/new.json?limit=100&after=t3_bbughr\n",
      "collected 997 posts ...\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "after = None\n",
    "list_of_afters = []\n",
    "\n",
    "for a in range(15):\n",
    "    if after == None:\n",
    "        current_url = url\n",
    "        if len(list_of_afters): # not empty\n",
    "            print('collected',len(posts),'posts ...')\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        if after in list_of_afters:\n",
    "            print('collected',len(posts),'posts ...')\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        list_of_afters.append(after)\n",
    "        current_url = url + '&after=' + after\n",
    "    print(current_url)\n",
    "    res = requests.get(current_url, headers={'User-agent': 'Pony Inc 1.0'})\n",
    "    \n",
    "    if res.status_code != 200:\n",
    "        print('Status error', res.status_code)\n",
    "        break\n",
    "    \n",
    "    current_dict = res.json()\n",
    "    current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "    posts.extend(current_posts)\n",
    "    after = current_dict['data']['after']\n",
    "    \n",
    "    # generate a random sleep duration to not look like a Denial-of-Service attack.\n",
    "    sleep_duration = random.randint(2,10)\n",
    "#     print(sleep_duration)\n",
    "    time.sleep(sleep_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save posts to file 'talesfromthecustomer.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(posts).to_csv('../data/talesfromthecustomer.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set URL for subreddit --- 'Tales From Your Server'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.reddit.com/r/TalesFromYourServer/new.json?limit=100'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratively retrieve 100 posts. Set maximum iterations to 15. Stop iterating if duplicate posts are detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/TalesFromYourServer/new.json?limit=100\n",
      "https://www.reddit.com/r/TalesFromYourServer/new.json?limit=100&after=t3_dhvc3l\n",
      "https://www.reddit.com/r/TalesFromYourServer/new.json?limit=100&after=t3_dfxcwh\n",
      "https://www.reddit.com/r/TalesFromYourServer/new.json?limit=100&after=t3_de3lgj\n",
      "https://www.reddit.com/r/TalesFromYourServer/new.json?limit=100&after=t3_dbond0\n",
      "https://www.reddit.com/r/TalesFromYourServer/new.json?limit=100&after=t3_da3ue5\n",
      "https://www.reddit.com/r/TalesFromYourServer/new.json?limit=100&after=t3_d7zu7b\n",
      "https://www.reddit.com/r/TalesFromYourServer/new.json?limit=100&after=t3_d5i06t\n",
      "https://www.reddit.com/r/TalesFromYourServer/new.json?limit=100&after=t3_d3j37f\n",
      "https://www.reddit.com/r/TalesFromYourServer/new.json?limit=100&after=t3_d14o67\n",
      "collected 996 posts ...\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "after = None\n",
    "list_of_afters = []\n",
    "\n",
    "for a in range(15):\n",
    "    if after == None:\n",
    "        current_url = url\n",
    "        if len(list_of_afters): # not empty\n",
    "            print('collected',len(posts),'posts ...')\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        if after in list_of_afters:\n",
    "            print('collected',len(posts),'posts ...')\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        list_of_afters.append(after)\n",
    "        current_url = url + '&after=' + after\n",
    "    print(current_url)\n",
    "    res = requests.get(current_url, headers={'User-agent': 'Pony Inc 1.0'})\n",
    "    \n",
    "    if res.status_code != 200:\n",
    "        print('Status error', res.status_code)\n",
    "        break\n",
    "    \n",
    "    current_dict = res.json()\n",
    "    current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "    posts.extend(current_posts)\n",
    "    after = current_dict['data']['after']\n",
    "    \n",
    "    # generate a random sleep duration to not look like a Denial-of-Service attack.\n",
    "    sleep_duration = random.randint(2,10)\n",
    "#     print(sleep_duration)\n",
    "    time.sleep(sleep_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save posts to file 'talesfromyourserver.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(posts).to_csv('../data/talesfromyourserver.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The raw data has been collected and saved. Kindly refer to notebook 02."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
